Metadata-Version: 2.1
Name: textembed
Version: 0.0.3
Summary: TextEmbed provides a robust and scalable REST API for generating vector embeddings from text. Built for performance and flexibility, it supports various sentence-transformer models, allowing users to easily integrate state-of-the-art NLP techniques into their applications. Whether you need embeddings for search, recommendation, or other NLP tasks, TextEmbed delivers with high efficiency.
Home-page: https://github.com/kevaldekivadiya2415/textembed
Author: Keval Dekivadiya
Author-email: kevaldekivadiya2415@gmail.com
License: Apache License 2.0
Keywords: Embedding
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.11.0
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: annotated-types==0.6.0
Requires-Dist: anyio==4.3.0
Requires-Dist: certifi==2024.2.2
Requires-Dist: charset-normalizer==3.3.2
Requires-Dist: click==8.1.7
Requires-Dist: dnspython==2.6.1
Requires-Dist: email_validator==2.1.1
Requires-Dist: fastapi==0.111.0
Requires-Dist: fastapi-cli==0.0.3
Requires-Dist: filelock==3.14.0
Requires-Dist: fsspec==2024.5.0
Requires-Dist: h11==0.14.0
Requires-Dist: httpcore==1.0.5
Requires-Dist: httptools==0.6.1
Requires-Dist: httpx==0.27.0
Requires-Dist: huggingface-hub==0.23.1
Requires-Dist: idna==3.7
Requires-Dist: Jinja2==3.1.4
Requires-Dist: joblib==1.4.2
Requires-Dist: markdown-it-py==3.0.0
Requires-Dist: MarkupSafe==2.1.5
Requires-Dist: mdurl==0.1.2
Requires-Dist: mpmath==1.3.0
Requires-Dist: networkx==3.3
Requires-Dist: numpy==1.26.4
Requires-Dist: orjson==3.10.3
Requires-Dist: packaging==24.0
Requires-Dist: pillow==10.3.0
Requires-Dist: prometheus-fastapi-instrumentator==7.0.0
Requires-Dist: prometheus_client==0.20.0
Requires-Dist: pydantic==2.7.1
Requires-Dist: pydantic_core==2.18.2
Requires-Dist: Pygments==2.18.0
Requires-Dist: python-dotenv==1.0.1
Requires-Dist: python-multipart==0.0.9
Requires-Dist: PyYAML==6.0.1
Requires-Dist: regex==2024.5.15
Requires-Dist: requests==2.31.0
Requires-Dist: rich==13.7.1
Requires-Dist: safetensors==0.4.3
Requires-Dist: scikit-learn==1.4.2
Requires-Dist: scipy==1.13.0
Requires-Dist: sentence-transformers==2.7.0
Requires-Dist: shellingham==1.5.4
Requires-Dist: sniffio==1.3.1
Requires-Dist: starlette==0.37.2
Requires-Dist: sympy==1.12
Requires-Dist: threadpoolctl==3.5.0
Requires-Dist: tokenizers==0.19.1
Requires-Dist: torch==2.3.0
Requires-Dist: tqdm==4.66.4
Requires-Dist: transformers==4.41.0
Requires-Dist: typer==0.12.3
Requires-Dist: typing_extensions==4.11.0
Requires-Dist: ujson==5.10.0
Requires-Dist: urllib3==2.2.1
Requires-Dist: uvicorn==0.29.0
Requires-Dist: uvloop==0.19.0
Requires-Dist: watchfiles==0.21.0
Requires-Dist: websockets==12.0

# TextEmbed - Embedding Inference Server

TextEmbed is a high-throughput, low-latency REST API designed for serving vector embeddings. It supports a wide range of sentence-transformer models and frameworks, making it suitable for various applications in natural language processing.

## Features

- **High Throughput & Low Latency:** Designed to handle a large number of requests efficiently.
- **Flexible Model Support:** Works with various sentence-transformer models.
- **Scalable:** Easily integrates into larger systems and scales with demand.
- **Batch Processing:** Supports batch processing for better and faster inference.
- **OpenAI Compatible REST API Endpoint:** Provides an OpenAI compatible REST API endpoint.

## Getting Started

### Prerequisites

Ensure you have Python 3.11 or higher installed. You will also need to install the required dependencies.

### Installation

1. Install the required dependencies:
    ```bash
    pip install -r requirements.txt
    ```

2. Start the TextEmbed server with your desired model:
    ```bash
    python3 -m textembed.server --model <Model Name>
    ```

    Replace `<Model Name>` with the name of the model you want to use.

3. For more information and additional options, run:
    ```bash
    python3 -m textembed.server --help
    ```

### Running with Docker (Recommended)
You can also run TextEmbed using Docker. The Docker image is available on Docker Hub.
```bash
docker run kevaldekivadiya/textembed:latest --help
```
This command will show the help message for the TextEmbed server, detailing the available options and usage.

For Example:
```bash
docker run -p 8000:8000 kevaldekivadiya/textembed:latest --model sentence-transformers/all-MiniLM-L6-v2 --port 8000
```

### Accessing the API

Once the server is running, you can access the API documentation via Swagger UI.
