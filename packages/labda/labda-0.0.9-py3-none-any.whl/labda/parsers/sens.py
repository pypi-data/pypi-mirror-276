import time
from datetime import datetime
from pathlib import Path

import pandas as pd

from ..logging import log_successfully_parsed_subject
from ..structure.subject import Metadata, Sensor, Subject, Vendor
from ..structure.validation.subject import SCHEMA, Column
from ..utils import (
    align_datetimes,
    filter_datetime,
    get_sampling_frequency,
    set_timezone,
)


def _parse_csv(path: Path) -> pd.DataFrame:
    df = pd.read_csv(
        path,
        engine="pyarrow",
        dtype={
            " general/nodata/time": "boolean",
            " activity/lying_sitting_rest/time": "boolean",
            " activity/lying_sitting_movement/time": "boolean",
            " activity/upright_stand/time": "boolean",
            " activity/upright_sporadic_walk/time": "boolean",
            " activity/upright_walk/time": "boolean",
            " activity/upright_moderate/time": "boolean",
            " activity/upright_run/time": "boolean",
            " activity/cycling/time": "boolean",
        },
    )

    # FIXME: Stupid thing to do, just remove whitespace from column names before anything.
    if "utc" in df.columns and " local" in df.columns:
        df.drop(columns=["utc", " local"], inplace=True)

    if " unixts" in df.columns:
        df.rename(columns={" unixts": "unixts"}, inplace=True)

    df[Column.DATETIME] = pd.to_datetime(df["unixts"], unit="ms", origin="unix")
    df[Column.WEAR] = ~df[" general/nodata/time"]

    df.drop(columns=["unixts", " general/nodata/time"], inplace=True)
    df.set_index(Column.DATETIME, inplace=True)

    df.rename(
        columns={" activity/intensity/count": Column.ACTIVITY_VALUE}, inplace=True
    )

    return df


def _infer_position(df: pd.DataFrame) -> None:
    df.loc[
        df[" activity/lying_sitting_rest/time"]
        | df[" activity/lying_sitting_movement/time"],
        Column.POSITION,
    ] = "sitting-lying"

    df.loc[
        df[" activity/upright_stand/time"]
        | df[" activity/upright_sporadic_walk/time"]
        | df[" activity/upright_walk/time"]
        | df[" activity/upright_moderate/time"]
        | df[" activity/upright_run/time"],
        Column.POSITION,
    ] = "standing"

    df.loc[df[" activity/cycling/time"], Column.POSITION] = "sitting"


def _infer_activity_intensity(df: pd.DataFrame) -> None:
    labels = ["sedentary", "light", "moderate", "vigorous", "very_vigorous"]
    cuts = [0, 2, 50, 75, 100, float("inf")]

    df[Column.ACTIVITY_INTENSITY] = pd.cut(
        df[Column.ACTIVITY_VALUE],
        bins=cuts,
        labels=labels,
        right=False,
        include_lowest=True,
    )


def _infer_steps(df: pd.DataFrame) -> None:
    df[Column.STEPS] = (
        df[" activity/steps/count"]
        + df[" activity/steps2/count"]
        + df[" activity/steps3/count"]
    )
    df[Column.STEPS] = df[Column.STEPS].round().astype("Int16")


def _infer_activity(df: pd.DataFrame) -> None:
    df.loc[df[" activity/cycling/time"], Column.ACTIVITY] = "bicycling"
    df.loc[df[" activity/lying_sitting_rest/time"], Column.ACTIVITY] = "resting"
    df.loc[df[" activity/upright_sporadic_walk/time"], Column.ACTIVITY] = (
        "sporadic_walking"
    )
    df.loc[df[" activity/upright_walk/time"], Column.ACTIVITY] = "walking"
    df.loc[df[" activity/upright_moderate/time"], Column.ACTIVITY] = "jogging"
    df.loc[df[" activity/upright_run/time"], Column.ACTIVITY] = "running"


def from_csv(
    path: str | Path,
    *,
    subject_id: str | None = None,
    start: datetime | None = None,
    end: datetime | None = None,
    sampling_frequency: float | None = None,
    timezone: str | None = None,
    sensor_id: str | None = None,
    vendor: Vendor = Vendor.SENS,
    model: str | None = None,
    serial_number: str | None = None,
    firmware_version: str | None = None,
) -> Subject:
    """
    This function is designed to process data activity CSV files generated by Sens sensors. Optionally, you can define a date and time range to download data for a specific timeframe. If no date range is provided (from/to), all data for the chosen device will be parsed.

    It infers certain information using Sens' classification algorithms; more details are available [here](https://support.sens.dk/hc/en-us/articles/15580259064093-Description-of-activity-categories).

    **Wear** is determined by checking the "nodata" column. A value of 0 indicates that the sensor was worn, while a value of 1 indicates that it wasn't.

    **Position** is determined by looking for values (not NA) in multiple data columns. Here's the logic it follows:

    - `sitting-lying` if values are in columns *lying_sitting_rest* or *lying_sitting_movement*,
    - `sitting` if *cycling*,
    - `standing` if *upright_stand*, *upright_sporadic_walk*, *upright_walk*, *upright_moderate* or *upright_run*.

    Number of **steps** is calculated by summing the values in columns *steps*, *steps2* and *steps3*.

    **Activity intensity** is calculated based on the vendor's activity value (metric). The values are binned into the following categories: *sedentary*, *light*, *moderate*, *vigorous*, *very_vigorous* based on the following thresholds: 0, 2, 50, 75, 100.

    **Activity** is determined by looking for values (not NA) in multiple data columns. Here's the logic it follows:

    - `bicycling` if values are in column *cycling*,
    - `resting` if *lying_sitting_rest*,
    - `sporadic_walking` if *upright_sporadic_walk*,
    - `walking` if *upright_walk*,
    - `jogging` if *upright_moderate*,
    - `running` if *upright_run*.

    The data will be parsed and validated according to the schema defined in the structure module.

    Args:
        path (str | Path): The path to the CSV file.
        subject_id (str, optional): The ID of the subject. If not provided, it will be set to the file name.
        start (datetime, optional): The start time of the data to fetch. If not provided, it will fetch all available data.
        end (datetime, optional): The end time of the data to fetch. If not provided, it will fetch all available data.
        sampling_frequency (float, optional): The sampling frequency of the data. If not provided, it will be infered from data.
        timezone (str, optional): The timezone of the data. If None it will be set to the local timezone. Otherwise, it will be set to the provided timezone.
        sensor_id (str, optional): The ID of the sensor. If not provided, it will be set to the file name.
        vendor (Vendor, optional): The vendor of the sensor.
        model (str, optional): The model of the sensor.
        serial_number (str, optional): The serial number of the sensor.
        firmware_version (str, optional): The firmware version of the sensor.


    Returns:
        Subject: A Subject object containing the fetched and processed dataframe containing information: datetime, wear, position, steps, activity_intensity, activity_value and activity.

    Raises:
        FileNotFoundError: File not found.
        ValueError: File format not CSV.

    Examples:
        Here's how to call the function with just the minimum required parameters.

        ```python
        from labda.parsers import Sens

        subject = Sens.from_csv(
            "jane_doe.csv",
        )
        ```
    """
    #

    if isinstance(path, str):
        path = Path(path)

    if not path.is_file():
        raise FileNotFoundError(f"File not found: {path}")

    if path.suffix != ".csv":
        raise ValueError(f"Invalid file format: {path.suffix}")

    df = _parse_csv(path)

    if timezone:
        df, timezone = set_timezone(df, ("UTC", timezone))
    else:
        timezone = time.tzname[0]
        df.index = df.index.tz_convert(timezone).tz_localize(None)  # type: ignore

    df = filter_datetime(df, start, end)

    if not sampling_frequency:
        sampling_frequency = get_sampling_frequency(df)

    df = align_datetimes(df, sampling_frequency)

    _infer_position(df)
    _infer_activity_intensity(df)
    _infer_steps(df)
    _infer_activity(df)

    # Order columns as defined in Column, remove extra columns
    columns = [col.value for col in Column]
    ordered_columns = [col for col in columns if col in df.columns]
    df = df[ordered_columns]

    df = SCHEMA.validate(df)

    subject_id = subject_id or path.stem
    sensor_id = sensor_id or path.stem

    sensor = Sensor(
        id=sensor_id,
        serial_number=serial_number,
        model=model,
        vendor=vendor,
        firmware_version=firmware_version,
    )

    metadata = Metadata(
        id=subject_id,
        sensor=[sensor],
        sampling_frequency=sampling_frequency,
        timezone=timezone,
    )

    subject = Subject(metadata=metadata, df=df)
    log_successfully_parsed_subject(subject, f"{__name__}.from_csv", path.name)

    return subject
