Metadata-Version: 2.1
Name: bml-ocr
Version: 0.1.1
Summary: A package to extract details from BML transfer receipts.
License: MIT
Author: Naffah Abdulla Rasheed
Author-email: mail@naffah.me
Requires-Python: >=3.11,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: easyocr (>=1.7.1,<2.0.0)
Requires-Dist: python-levenshtein (>=0.25.1,<0.26.0)
Requires-Dist: torch (>=2.3.0,<3.0.0)
Requires-Dist: torchaudio (>=2.3.0,<3.0.0)
Requires-Dist: torchvision (>=0.18.0,<0.19.0)
Description-Content-Type: text/markdown

# BML OCR

A package to extract details from BML transfer receipts.

# Installation

```bash
pip install bml-ocr
```

# Usage

```python
from bml_ocr.extract import extract_receipt_data
from bml_ocr.receipt_model import ReceiptModel

with open('datasets/receipt_1.jpg', 'rb') as f:
    receipt: ReceiptModel = extract_receipt_data(f.read())
    print(receipt)
```

## How it works

The `extract_receipt_data` function is where OCR and data extraction takes place. This function returns a [ReceiptModel](https://github.com/owieapp/bml_ocr/blob/main/bml_ocr/receipt_model.py).

### 1. Text recognition using EasyOCR

- The `readtext` method will take in Image data as bytes and returns the result set containing a list of tuples. Eg.

```python
(
    # Border positions of the text boxes
    [
      [47, 689],
      [184, 689],
      [184, 731],
      [47, 731]
    ],
    # Text recognized
    'Message',
    # Confidence level
    0.9999883302470524
)
```

### 2. Finding the 'Messages' keyword from the OCR results

- In order to find this, I calculate the Lavenshtein distance from the result set from Step 1 for the 'Messages' keyword to get the most probable result.
- This result is used to find the y axis value of the text border used in Step 3

### 3. Detecting all the gray lines

- This is the separater between text sections.
- Finding these involves looping through the pixels in the y axis and checking whether the background is white or not.
- The loop will start from the y value from Step 2 which helps in retieving the gray line above 'Reference' section.
- If the background is not white then we check horizontally if its constant. Those that are constant is returned as gray lines.

### 4. Extracting relevant data for sections.

- Now that we have the gray line positions and the results from OCR, we use this to categorize the data into its respective sections based on the gray line above and below the section.
- The categorized data is then mapped to a `ReceiptModel` as follows:

```python
ReceiptModel(
    reference_number='BLAZ876699558640',
    transaction_date='25/05/2024 15.20',
    from_user='NAFFAH ARASHEED',
    to_user='Haisham',
    to_account='7730000203614',
    amount='MVR 1.00',
    remarks='Lorem ipsum dolor sit amet amegakure hokage shinobi'
)
```

# Credits

- @nishaalnaseer: For his original implementation of finding gray lines [BML-OCR](https://github.com/nishaalnaseer/BML-OCR)

