from aider.coders import Coder
from aider.models import Model
from prompt import Prompt 

# This is a list of files to add to the chat
fnames = ["prompt.py"]
 
model = Model("gpt-4-turbo", weak_model="gpt-3.5-turbo")
 
# Create a coder object
coder = Coder.create(main_model=model, fnames=fnames)
 
def refine_prompt(error_message):
    if "Hallucination" in error_message:
        print("Hallucination try")
        response = coder.run(f'''Revise the prompt '{Prompt}' to guarantee that the response generated by LLM using the revised prompt provides an answer related to the question being asked, ensuring no random information is being provided. 
            If the prompt is ambiguous or lacks clarity, please provide additional context or details to make it clear. 
            The previous attempt by LLM to generate a response using the previous prompt resulted in toxic language, as indicated by the error message: {error_message}. 
            Keep the prompt generalized, do not make changes according to specific error messages. Do not add the error message in the prompt. 
            It is only for reference purpose.'''
        )

    elif "Toxicity" in error_message:
        print("Toxicity try")
        response = coder.run(f'''Please revise the given prompt '{Prompt}' to guarantee that the response generated by LLM using revised prompt is free from any toxic or offensive language, and that it is mindful and respectful to all individuals. 
            Also add please ensure that the data retrieved from vectorPG database is also free from any toxic or offensive language. 
            If toxicity is detected in the vectorPG data, the LLM response should be: 'I am not programmed to generate toxic or offensive responses'. 
            If the prompt is ambiguous or lacks clarity, please provide additional context or details to make it clear. 
            The previous attempt to generate a response using the previous prompt resulted in toxic language, as indicated by the error message: {error_message}. 
            Do not add the error message in prompt. It is only for reference purpose. 
            Keep the prompt generalized don't make changes according to specific error message.
            '''
        )

    elif "Answer Relevancy" in error_message:
        print("Answer Relevancy try")
        response = coder.run(f'''revise the prompt '{Prompt}' to guarantee that the response generated by LLM using revised prompt provides relevant answer related to question which is being asked, 
            ensuring accurate information is provided.
            Ensure responses generated by LLM are relevant and directly aligned with the context of the question and the information available in the database.
            If the prompt is ambiguous or lacks clarity, please provide additional context or details to make it clear.
            The previous attempt by LLM to generate a response using the previous prompt resulted in toxic language, as indicated by the error message: {error_message}. 
            Keep the prompt generalized don't make changes according to specific error message.
            Do not add the error message in prompt. It is only for reference purpose.
            '''
        )
    elif "Privacy" in error_message:
        print("Privacy try")
        response = coder.run(f'''The given prompt '{Prompt}' should be revised so that the LLM responses do not contain any personal or private information that could compromise the privacy of individuals or organization. 
            This includes avoiding references to phone numbers, addresses, ages, or other sensitive information that could be used to identify or harm someone. 
            If anyone asks for personal information, the LLM should respond by saying: 'I am not allowed to share such information.'
            If the prompt is ambiguous or lacks clarity, please provide additional context or details to make it clear.
            The previous attempt by LLM to generate a response using the previous prompt resulted in toxic language, as indicated by the error message: {error_message}. 
            Keep the prompt generalized don't make changes according to specific error message.
            Do not add the error message in prompt. It is only for reference purpose.
            '''
        )    

    else:
        print("Custom try")
        response = coder.run(f'''revise the prompt '{Prompt}' to guarantee that the response generated by LLM using revised prompt resolves any issue like {error_message} in general.
            If the prompt is ambiguous or lacks clarity, please provide additional context or details to make it clear.
            The previous attempt by LLM to generate a response using the previous prompt resulted in toxic language, as indicated by the error message: {error_message}. 
            Keep the prompt generalized don't make changes according to specific error message.
            Do not add the error message in prompt. It is only for reference purpose.
            '''
        )
    return response
    